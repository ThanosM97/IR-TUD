{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative comparison of contextual vs word embedding approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyserini.index import IndexReader\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER ='.'\n",
    "DATA_PATH = './data' # path to the data files\n",
    "OUTPUT_PATH = './outputs' # path to where the outputs will be saved\n",
    "\n",
    "WORD_RANKINGS_FILE = 'glove_euclidean_ranking.txt' # path to word embedding model's rankings\n",
    "CONTEXTUAL_RANKINGS_FILE = 'distilbert_cosine_similarity.txt' # path to contextual embedding model's rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "qrels = pd.read_csv(DATA_PATH + '2019qrels-pass.txt',sep=' ', header=None, names = [\"query_id\", \"Q0\", \"passage_id\", \"relevance\"])\n",
    "test_queries = pd.read_csv(DATA_PATH + 'msmarco-test2019-queries.tsv',sep='\\t', header=None, names = [\"query_id\", \"query\"])\n",
    "passages = pd.read_csv(DATA_PATH + 'collection.tsv',sep='\\t', header=None, names = [\"passage_id\", \"passage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_results = pd.read_csv(WORD_RANKINGS_FILE, sep='\\t', header=None, names = [\"query_id\", \"passage_id\", \"rank\"])\n",
    "cont_results = pd.read_csv(CONTEXTUAL_RANKINGS_FILE, sep='\\t', header=None, names = [\"query_id\", \"passage_id\", \"rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make joins to take query and passage contents\n",
    "qrels = pd.merge(qrels, test_queries,  how='left', left_on=['query_id'], right_on = ['query_id'])\n",
    "qrels = pd.merge(qrels, passages,  how='left', left_on=['passage_id'], right_on = ['passage_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find highly relevant passages returned by both word and contextual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly relevant (relevance >= 2)\n",
    "relevant = qrels.loc[(qrels['relevance'] >= 2)].reset_index()\n",
    "\n",
    "# Inner join to find irrelevant passages that were returned\n",
    "cont_returned = pd.merge(cont_results, relevant,  how='inner', left_on=['query_id','passage_id'], right_on = ['query_id','passage_id']).drop(['index','Q0'], axis=1)\n",
    "word_returned = pd.merge(word_results, relevant,  how='inner', left_on=['query_id','passage_id'], right_on = ['query_id','passage_id']).drop(['index','Q0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find higly relevant passages that word methods ranked at least 800 positions lower than contextual methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Find unique query-passage combinations \n",
    "unique_tuples = []\n",
    "unique = word_returned[['query_id','passage_id']].drop_duplicates()\n",
    "for i in range(unique.shape[0]):\n",
    "    unique_tuples.append((unique.at[i,\"query_id\"],unique.at[i,\"passage_id\"]))\n",
    "\n",
    "\n",
    "data = []\n",
    "# For each unique query-passage combination\n",
    "for i in range(len(unique_tuples)):\n",
    "    qid = unique_tuples[i][0]\n",
    "    pid = unique_tuples[i][1]\n",
    "\n",
    "    # Find index of relevant query-passage pair in the rankings of both the word and contextual embedding models\n",
    "    index1 = word_returned.loc[(word_returned['query_id'] == qid) & (word_returned['passage_id'] == pid)].reset_index()[\"index\"].values[0]\n",
    "    index2 = cont_returned.loc[(cont_returned['query_id'] == qid) & (cont_returned['passage_id'] == pid)].reset_index()[\"index\"].values[0]\n",
    "\n",
    "    # Append to results query-passage combinations, where the ranking of word embedding models was 800 positions lower than the corresponding ranking od contextual\n",
    "    if word_returned.at[index1,'rank'] - cont_returned.at[index2,'rank'] > 800:\n",
    "        data.append(cont_returned.loc[index2]) \n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['query_id', 'passage_id', 'rank', 'query', 'passage']).reset_index().drop([\"index\", \"rank\"], axis=1)\n",
    "df = pd.merge(df, cont_returned,  how='left', left_on=['query_id','passage_id'], right_on = ['query_id','passage_id']).drop(['query_y','passage_y'], axis=1).rename(columns={\"rank\": \"cont_rank\", \"query_x\": \"query\", \"passage_x\": \"passage\"})\n",
    "df = pd.merge(df, word_returned,  how='left', left_on=['query_id','passage_id'], right_on = ['query_id','passage_id']).drop(['query_y','passage_y'], axis=1).rename(columns={\"rank\": \"word_rank\", \"query_x\": \"query\", \"passage_x\": \"passage\"})\n",
    "df = df.rename(columns={\"relevance_y\": \"relevance\"}).drop([\"relevance_x\",\"query_id\",\"passage_id\"],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(OUTPUT_PATH + \"comparison_contextual_vs_word.json\", orient=\"records\", indent=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9306f36d181eec8a686c142a66ce2822771d99ba786440ee66f26e3c8acd536a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
